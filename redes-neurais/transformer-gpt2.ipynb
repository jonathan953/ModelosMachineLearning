{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Chatbot Transformer com GPT-2\n",
    "\n",
    "## 📌 Visão Geral\n",
    "Este projeto implementa um chatbot interativo utilizando o modelo **GPT-2**, desenvolvido pela OpenAI. Ele gera respostas coerentes para entradas do usuário, permitindo conversas dinâmicas baseadas em inteligência artificial.\n",
    "\n",
    "## 🛠 Requisitos\n",
    "Antes de executar o chatbot, certifique-se de ter as seguintes dependências instaladas:\n",
    "\n",
    "```bash\n",
    "pip install torch transformers\n",
    "```\n",
    "\n",
    "## 🚀 Como Executar\n",
    "Basta rodar o seguinte comando no terminal:\n",
    "\n",
    "```bash\n",
    "python chatbot.py\n",
    "```\n",
    "\n",
    "Durante a execução, digite suas mensagens no console e receba respostas geradas pelo modelo GPT-2. Para encerrar a interação, digite **\"sair\"**.\n",
    "\n",
    "## 📜 Código-Fonte\n",
    "O chatbot é composto por três funções principais:\n",
    "\n",
    "### 1️⃣ **Carregar Modelo**\n",
    "\n",
    "A função `carregar_modelo()` baixa e carrega o modelo GPT-2 e seu tokenizer.\n",
    "\n",
    "### 2️⃣ **Gerar Resposta**\n",
    "\n",
    "A função `gerar_resposta()` recebe a entrada do usuário, processa o texto com o modelo e retorna uma resposta gerada.\n",
    "\n",
    "### 3️⃣ **Iniciar o Chat**\n",
    "\n",
    "A função `iniciar_chat()` cria um loop interativo no terminal, permitindo que o usuário converse com o chatbot.\n",
    "\n",
    "## 🎛 Configurações do Modelo\n",
    "As configurações do GPT-2 podem ser ajustadas para alterar o comportamento das respostas:\n",
    "\n",
    "- `temperature=0.7`: Controla a aleatoriedade. Valores menores tornam as respostas mais previsíveis.\n",
    "- `top_p=0.9`: Usa amostragem do topo da distribuição de probabilidade.\n",
    "- `repetition_penalty=1.2`: Penaliza repetições excessivas, tornando as respostas mais diversificadas.\n",
    "- `max_length=100`: Define o tamanho máximo da resposta gerada.\n",
    "\n",
    "## ⚡ Exemplo de Uso\n",
    "```bash\n",
    "🤖 Chatbot Transformer iniciado! Digite 'sair' para encerrar.\n",
    "\n",
    "Você: Olá, como você está?\n",
    "🤖 Chatbot: Olá! Estou bem, obrigado por perguntar. Como posso te ajudar hoje?\n",
    "\n",
    "Você: Quem criou você?\n",
    "🤖 Chatbot: Fui criado usando o modelo GPT-2, desenvolvido pela OpenAI!\n",
    "\n",
    "Você: sair\n",
    "🤖 Chatbot encerrado. Até mais!\n",
    "```\n",
    "\n",
    "## 📌 Notas\n",
    "- O modelo **GPT-2** pode gerar respostas inconsistentes ocasionalmente.\n",
    "- Para um chatbot mais avançado, considere usar modelos maiores como `EleutherAI/gpt-neo-1.3B`.\n",
    "\n",
    "## 📖 Referências\n",
    "- [Transformers Library](https://huggingface.co/transformers/)\n",
    "- [OpenAI GPT-2](https://openai.com/research/gpt-2)\n",
    "\n",
    "---\n",
    "Criado com ❤️ utilizando **Transformers** e **PyTorch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Chatbot Transformer iniciado! Digite 'sair' para encerrar.\n",
      "🤖 Chatbot: what is the distance from the earth to the moon?\n",
      "The answer: The Earth's orbit around the sun. This means that it orbits about a third of its length, and so on until we reach our destination at some point in time (the end). It also makes sense for us not only to be able see this planet but even more importantly how far away you are when looking down into space! We can't just look up straight outta there; if anything goes wrong with your telescope or\n",
      "🤖 Chatbot: what is your favorite food?\n",
      "I love the chicken. I like it a lot, but not as much because of its flavor and texture. It's just so good! The only thing that makes me happy about this dish are my friends who have been eating here for years (and they're all very nice). They've always loved to eat with us at night when we go out on our way home from work or school; sometimes even in their cars while driving around town trying new things…but\n",
      "🤖 Chatbot: Do you kill chicken?\n",
      "I don't know. I'm not sure what to do with it, but if they're going out of their way to get me killed then that's fine too.\" She looked at him and nodded her head in agreement before continuing on the path she had just taken up as a matter-of factly nonchalant \"You can go back home now or we'll have some fun!\"\n",
      "\n",
      " (She didn' t want anyone else around.) The two girls were sitting\n",
      "🤖 Chatbot: Escape from the Dark is a game about escaping. It's not an easy task, but it does require some patience and skill to master (and you'll need that in order for this one).\n",
      "The first thing I did was go through all of my favorite games on Steam before playing Escape From The Darkness: A Tale Of Two Cities . This time around though, there are two new ones coming out as well! One will be called \"A New World\" which means we're going to explore\n",
      "🤖 Chatbot encerrado. Até mais!\n"
     ]
    }
   ],
   "source": [
    "# 📌 Importando as bibliotecas necessárias\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 🔹 1. Carregar o modelo e o tokenizer do GPT-2\n",
    "def carregar_modelo():\n",
    "    modelo_nome = \"gpt2\"  # Pode ser trocado por \"EleutherAI/gpt-neo-1.3B\" para um modelo maior\n",
    "    tokenizer = AutoTokenizer.from_pretrained(modelo_nome)\n",
    "    modelo = AutoModelForCausalLM.from_pretrained(modelo_nome)\n",
    "    return modelo, tokenizer\n",
    "\n",
    "# 🔹 2. Gerar resposta a partir da entrada do usuário\n",
    "def gerar_resposta(modelo, tokenizer, entrada_usuario, max_length=100):\n",
    "    entrada_ids = tokenizer.encode(entrada_usuario, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        saida_ids = modelo.generate(\n",
    "            entrada_ids,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            temperature=0.7,  # Controla a criatividade das respostas\n",
    "            top_p=0.9,  # Amostragem do topo da distribuição de probabilidade\n",
    "            repetition_penalty=1.2  # Penaliza repetições excessivas\n",
    "        )\n",
    "\n",
    "    resposta = tokenizer.decode(saida_ids[0], skip_special_tokens=True)\n",
    "    return resposta\n",
    "\n",
    "# 🔹 3. Criar loop de interação (chatbot)\n",
    "def iniciar_chat():\n",
    "    modelo, tokenizer = carregar_modelo()\n",
    "    print(\"🤖 Chatbot Transformer iniciado! Digite 'sair' para encerrar.\")\n",
    "\n",
    "    while True:\n",
    "        entrada_usuario = input(\"\\nVocê: \")\n",
    "        if entrada_usuario.lower() == \"sair\":\n",
    "            print(\"🤖 Chatbot encerrado. Até mais!\")\n",
    "            break\n",
    "\n",
    "        resposta = gerar_resposta(modelo, tokenizer, entrada_usuario)\n",
    "        print(f\"🤖 Chatbot: {resposta}\")\n",
    "\n",
    "# 🚀 Iniciar o chat interativo\n",
    "if __name__ == \"__main__\":\n",
    "    iniciar_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
