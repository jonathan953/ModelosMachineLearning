{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ  RegressÃ£o Lasso (L1) no **Boston Housing Dataset**\n",
    "\n",
    "## ğŸ“Œ Sobre o Dataset\n",
    "O **Boston Housing Dataset** Ã© um conjunto de dados clÃ¡ssico utilizado para prever o preÃ§o mÃ©dio das casas em diferentes bairros de Boston. O objetivo deste projeto Ã© aplicar **RegressÃ£o Lasso (L1)** para encontrar os principais fatores que impactam no valor dos imÃ³veis.\n",
    "\n",
    "As caracterÃ­sticas do dataset incluem:\n",
    "- ğŸ¡ **ZN** â€“ ProporÃ§Ã£o de terrenos residenciais  \n",
    "- ğŸ­ **INDUS** â€“ ProporÃ§Ã£o de terrenos industriais  \n",
    "- ğŸš¦ **NOX** â€“ ConcentraÃ§Ã£o de poluentes no ar  \n",
    "- ğŸ“ **RM** â€“ NÃºmero mÃ©dio de quartos por residÃªncia  \n",
    "- ğŸŒ **DIS** â€“ DistÃ¢ncia dos centros comerciais  \n",
    "- ğŸ“ **PTRATIO** â€“ Taxa de alunos por professor  \n",
    "- ğŸ“Š **LSTAT** â€“ Percentual de classe baixa na populaÃ§Ã£o  \n",
    "- ğŸ’² **MEDV** â€“ Valor mediano das casas (variÃ¡vel alvo)  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸš€ O que este cÃ³digo faz?\n",
    "Este cÃ³digo implementa um modelo de **RegressÃ£o Lasso (L1)** para prever os preÃ§os dos imÃ³veis. Ele inclui:\n",
    "\n",
    "âœ” **Carregamento e visualizaÃ§Ã£o do dataset**  \n",
    "âœ” **AnÃ¡lise exploratÃ³ria e matriz de correlaÃ§Ã£o**  \n",
    "âœ” **NormalizaÃ§Ã£o e transformaÃ§Ã£o dos dados** (StandardScaler e PowerTransformer)  \n",
    "âœ” **Ajuste de hiperparÃ¢metros** com **GridSearchCV**  \n",
    "âœ” **Treinamento do modelo de regressÃ£o Lasso (L1)**  \n",
    "âœ” **AvaliaÃ§Ã£o do modelo** com mÃ©tricas como **MAE, RMSE, RÂ² e acurÃ¡cia baseada na margem de erro**  \n",
    "âœ” **VisualizaÃ§Ãµes com grÃ¡ficos de erro, dispersÃ£o e comparaÃ§Ã£o entre prediÃ§Ãµes e valores reais**  \n",
    "âœ” **Teste com novos dados para prever o preÃ§o estimado de uma casa**  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ Como rodar o cÃ³digo?\n",
    "Antes de rodar o cÃ³digo, certifique-se de ter as bibliotecas instaladas:\n",
    "\n",
    "```bash\n",
    "pip install numpy pandas scikit-learn seaborn matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ğŸ”¹ 1. Carregar o dataset BOSTON HOUSING\n",
    "df = fetch_openml(name=\"boston\", version=1, as_frame=True).frame\n",
    "\n",
    "# Renomear a variÃ¡vel alvo\n",
    "df.rename(columns={'MEDV': 'target'}, inplace=True)\n",
    "\n",
    "# Exibe os cabeÃ§alho dos dados\n",
    "print(df.head(5))\n",
    "\n",
    "# ğŸ”¹ 2. AnÃ¡lise ExploratÃ³ria com Heatmap de CorrelaÃ§Ã£o\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de CorrelaÃ§Ã£o das VariÃ¡veis')\n",
    "plt.show()\n",
    "\n",
    "# ğŸ”¹ 3. Separar os dados em treino e teste (Holdout)\n",
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "\n",
    "# ğŸ”¹ 4. NormalizaÃ§Ã£o e TransformaÃ§Ã£o dos dados\n",
    "scaler = StandardScaler()\n",
    "power_transformer = PowerTransformer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_transformed = power_transformer.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ğŸ”¹ 5. Ajuste de HiperparÃ¢metros com GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': np.logspace(-4, 1, 50),\n",
    "    'max_iter': [1000, 5000, 10000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(), param_grid, cv=5, scoring='r2', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor modelo encontrado\n",
    "best_alpha = grid_search.best_params_['alpha']\n",
    "best_max_iter = grid_search.best_params_['max_iter']\n",
    "best_tol = grid_search.best_params_['tol']\n",
    "\n",
    "modelo = Lasso(alpha=best_alpha, max_iter=best_max_iter, tol=best_tol)\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "print(f\"ğŸ” Melhor Alpha encontrado: {best_alpha}\")\n",
    "print(f\"ğŸ” Melhor Max Iter: {best_max_iter}\")\n",
    "print(f\"ğŸ” Melhor TolerÃ¢ncia: {best_tol}\")\n",
    "\n",
    "# ğŸ”¹ 6. Fazer previsÃµes\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "# ğŸ”¹ 7. AvaliaÃ§Ã£o do Modelo\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# CÃ¡lculo da acurÃ¡cia baseada na margem de erro de 10%\n",
    "acuracia = np.mean(np.abs(y_pred - y_test) / y_test < 0.1)\n",
    "\n",
    "print(f\"ğŸ“Š MAE: {mae:.4f}\")\n",
    "print(f\"ğŸ“Š RMSE: {rmse:.4f}\")\n",
    "print(f\"ğŸ“Š RÂ²: {r2:.4f}\")\n",
    "print(f\"ğŸ“Š AcurÃ¡cia margem de erro: {acuracia:.2%}\")\n",
    "\n",
    "# ğŸ”¹ 8. GrÃ¡ficos de VisualizaÃ§Ã£o\n",
    "\n",
    "## ğŸ“Œ GrÃ¡fico de DistribuiÃ§Ã£o dos Erros\n",
    "residuos = y_test - y_pred\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(residuos, bins=30, kde=True, color=\"purple\")\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Erro de PrevisÃ£o\")\n",
    "plt.ylabel(\"FrequÃªncia\")\n",
    "plt.title(\"DistribuiÃ§Ã£o dos Erros do Modelo\")\n",
    "plt.show()\n",
    "\n",
    "## ğŸ“Œ GrÃ¡fico de PrevisÃ£o vs Real\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.7, color=\"blue\")\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--')\n",
    "plt.xlabel(\"Valores Reais\")\n",
    "plt.ylabel(\"Valores Preditos\")\n",
    "plt.title(\"Lasso Regression - PrevisÃ£o vs Real\")\n",
    "plt.show()\n",
    "\n",
    "## ğŸ“Œ GrÃ¡fico de ComparaÃ§Ã£o entre Predito e Real\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(y_test.values, label='Valores Reais', linestyle='-', color='blue', alpha=0.6)\n",
    "plt.plot(y_pred, label='Valores Preditos', linestyle='--', color='red', alpha=0.7)\n",
    "plt.xlabel(\"Amostras\")\n",
    "plt.ylabel(\"PreÃ§o da Casa\")\n",
    "plt.title(\"ComparaÃ§Ã£o entre PrevisÃ£o e Real\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ğŸ”¹ 9. Teste com Novos Dados\n",
    "novos_dados = np.array([[0.2, 18.0, 2.3, 0.0, 0.4, 6.2, 55.0, 5.0, 3.0, 240.0, 16.0, 390.0, 5.0]])\n",
    "novos_dados_scaled = scaler.transform(novos_dados)\n",
    "novos_dados_transformed = power_transformer.transform(novos_dados_scaled)\n",
    "previsao_nova = modelo.predict(novos_dados_transformed)\n",
    "\n",
    "print(f\"\\nğŸ”® PrevisÃ£o para novos dados: ${previsao_nova[0]:.2f} (mediana das casas)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
